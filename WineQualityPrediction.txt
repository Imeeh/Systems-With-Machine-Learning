import sys

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.np_utils import to_categorical
import matplotlib.pylab as plt

RED_WINE_DATASET_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
WHITE_WINE_DATASET_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'

### PARAMETERS TO BE EXPERIMENTED WITH ###
LAYER_UNITS_1 = 120 # number of neurons in the first layer of neural network
LAYER_UNITS_2 = 80  # number of neurons in the second layer of neural network
EPOCHS = 300        # number of iterations after which the learing finishes 
BATCH_SIZE = 32     # batch size after which weights are updated

# splits the datasets in split1
def get_split_1(X, Y):
    x_train, x_val_test, y_train, y_val_test = train_test_split(X, Y, train_size=0.70)
    x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, train_size=0.50)

    return x_train, x_val, x_test, y_train, y_val, y_test

# splits the datasets in split2
def get_split_2(X, Y):
    x_train, x_val_test, y_train, y_val_test = train_test_split(X, Y, train_size=0.70)
    x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, train_size=0.50)
    x_train, x_val, x_test = normalize_sets(x_train, x_val, x_test)

    return x_train, x_val, x_test, y_train, y_val, y_test

# splits the datasets in split3
def get_split_3(X, Y):
    x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.85)
    _, x_val, _, y_val = train_test_split(x_train, y_train, test_size=0.17)

    x_train, x_val, x_test = normalize_sets(x_train, x_val, x_test)
    return x_train, x_val, x_test, y_train, y_val, y_test

# prepare the data
def prepare_wine_data(wine_dataset_url):
    wines = pd.read_csv(wine_dataset_url, delimiter=";")
    X = wines.iloc[:, 0:-1]
    y = wines['quality'].astype(int)
    Y_categorical = to_categorical(y, num_classes=10)

    return X, Y_categorical

# prepare definition a definition of NN model
def cnn_build_model():
    model = Sequential()
    model.add(Dense(LAYER_UNITS_1, activation='relu', input_shape=(11,)))
    model.add(Dense(LAYER_UNITS_2, activation='relu'))
    # model.add(Dense(LAYER_UNITS_3, activation='relu'))
    model.add(Dense(10, activation='sigmoid'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    return model

# Conduct learing of the model
def train_model(x_train, y_train, x_val, y_val):
    model = cnn_build_model()
    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)

    return model

# normalize datasets with StanardScaler
def normalize_sets(*datasets):
    scaler = StandardScaler().fit(datasets[0])
    for ds in datasets:
        yield scaler.transform(ds)

# prints accuracy plot of the learnt model. Paramter 'type' is wine type red/white for title purposes. 
def show_accuracy_plot(model, type):
    plt.figure(1)
    plt.plot(model.history.history['accuracy'])
    plt.plot(model.history.history['val_accuracy'])
    plt.title(f'{type} - model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'val'], loc='upper left')
    plt.show()

# prints loss plot of the learnt model. Paramter 'type' is wine type red/white for title purposes. 
def show_loss_plot(model, type):
    plt.figure(2)
    plt.plot(model.history.history['loss'])
    plt.plot(model.history.history['val_loss'])
    plt.title(f'{type} - model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'val'], loc='upper left')
    plt.show()

# prints final evaluations of the model for each of subsets.
def evaluates(model, X_train, X_val, X_test, Y_train, Y_val, Y_test):
    loss, accuracy = model.evaluate(X_train, Y_train)
    print("TRAIN DATASET:\tloss %.3f\taccuracy %.3f" % (loss, accuracy))

    loss, accuracy = model.evaluate(X_val, Y_val)
    print("VALIDATION DATASET:\tloss %.3f\taccuracy %.3f" % (loss, accuracy))

    loss, accuracy = model.evaluate(X_test, Y_test)
    print("TEST DATASET:\tloss %.3f\taccuracy %.3f" % (loss, accuracy))


def main(argv):
    ### CHOOSE NUMBER OF SPLIT HERE ###
    split_no = 2

    if split_no == 1:
        get_split = get_split_1
        subset = 1

    elif split_no == 3:
        get_split = get_split_3
        subset = 3
    else:
        get_split = get_split_2
        subset = 2


    ### CHOOSE RED/WHITE WINES HERE ###

    # X, Y = prepare_wine_data(WHITE_WINE_DATASET_URL)
    # color = 'white'

    X, Y = prepare_wine_data(RED_WINE_DATASET_URL)
    color = 'red'

    X_train, X_val, X_test, Y_train, Y_val, Y_test = get_split(X, Y)
    model = train_model(X_train, Y_train, X_val, Y_val)

    show_accuracy_plot(model, f'subset{subset} - {color} wines')
    show_loss_plot(model, f'subset{subset} - {color} wines')

    evaluates(model, X_train, X_val, X_test, Y_train, Y_val, Y_test)

if __name__ == "__main__":
    main(sys.argv[1:])
    
    // https://github.com/Imeeh/Systems-With-Machine-Learning/edit/main/WineQualityPrediction.txt
